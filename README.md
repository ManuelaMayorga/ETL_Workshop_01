# Workshop_01 - ETL
Autor: [@ManuelaMayorga](https://github.com/ManuelaMayorga)

## Welcome

The beginning of this work consisted of the analysis and manipulation of data contained in a CSV file with 50,000 rows of randomly generated information on participants in selection processes. Throughout this process, specific technologies were used in the work instructions, including:  
- _Python_ <img src="https://cdn-icons-png.flaticon.com/128/3098/3098090.png" alt="Python" width="21px" height="21px"> 
- _Jupyter Notebook_  <img src="https://upload.wikimedia.org/wikipedia/commons/thumb/3/38/Jupyter_logo.svg/883px-Jupyter_logo.svg.png" alt="Jupyer" width="21px" height="21px">
- _PostgreSQL_ as the relational database management system (this was chosen by personal preference). <img src="https://cdn-icons-png.flaticon.com/128/5968/5968342.png" alt="Postgres" width="21px" height="21px">


## Objectives:

1. Migrate data from CSV file to PostgresQL database using SQLAlchemy.
2. Analyze and manipulate the data stored in the database.
3. Visualizations in Power BI:  
  - Hires by technology.
  - Hires by year.
  - Hires by seniority (level of experience).
  - Hires by country over years

## Description of `candidates.csv` file columns

50,000 rows and 10 columns, take into account that is randomly generated information

- First Name - Object
- Last Name - Object
- Email - Object
- Country - Object
- Application Date - Object
- Yoe (Years Of Experience) - Integer
- Seniority - Object
- Technology - Object
- Code Challenge Score - Integer
- Technical Interview - Integer

## How to run this project

First of all here is the requierements

Install Python : [Python Downloads](https://www.python.org/downloads/)
Install PostgreSQL : [PostgreSQL Downloads](https://www.postgresql.org/download/)

